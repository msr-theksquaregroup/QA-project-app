\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\geometry{a4paper, margin=2.54cm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{array}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

\bibliographystyle{plain}
\title{Project-X: Agent Development Report}
\author{[Developer Name]}
\date{July 21, 2025}

\begin{document}

\maketitle

\begin{abstract}
This report documents the development of the [Agent Name] Agent, a critical component of the Project-X MVP, designed to operate within a LangGraph environment using pre-trained Ollama models. The agent’s role is to [briefly describe agent’s purpose, e.g., parse user prompts, generate synthetic data]. This document details the agent’s design, implementation, testing, and integration, providing a comprehensive guide for future developers to replicate or extend the work. The report follows a scientific format, adhering to British English standards without contractions, as specified for Project-X documentation.

\textbf{Keywords}: Project-X, LangGraph, Ollama, [Agent-specific keywords, e.g., synthetic data, PyCaret, business rules].
\end{abstract}

\section{Introduction}
This report outlines the development process of the [Agent Name] Agent, one of eight agents in the Project-X MVP, aimed at delivering a system for automated data processing, machine learning model creation, and business rule application within a 6-week timeline starting July 21, 2025. All documentation must be written in British English, avoiding contractions (e.g., use ``is not'' instead of ``isn't'') to ensure standardisation across the project.

The [Agent Name] Agent is responsible for [describe agent’s role, e.g., parsing user prompts into structured inputs]. The author’s additional role in the team is [describe team role, e.g., Frontend Developer, Tech Lead], contributing to [briefly describe additional contributions, e.g., UI design, system integration]. This report provides a rigorous description of the agent’s functionality, implementation, and testing, ensuring that another developer can fully understand and replicate the work.

\textbf{Expected Content}: Provide a brief overview of the agent’s purpose within the Project-X pipeline, its significance, and how it aligns with the project’s goals (e.g., fraud detection, supply chain optimisation). Mention the author’s team role and contributions beyond agent development. Include references to relevant literature or tools (e.g., \texttt{pycaret}, \texttt{faker}, LangGraph) if applicable.

\section{Methodology}
This section describes the design methodology for the [Agent Name] Agent, including its role in the LangGraph pipeline, inputs, outputs, and integration strategy.

\subsection{Agent Role and Goal}
The [Agent Name] Agent is designed to [describe specific goal, e.g., generate synthetic datasets based on user specifications]. Its role in the pipeline is to [explain position, e.g., process inputs from the User Prompt Parser Agent and provide outputs for the EDA Agent].

\textbf{Expected Content}: Detail the agent’s primary objective and its position in the sequential pipeline. Explain how it contributes to the overall MVP functionality (e.g., enabling automated model training).

\subsection{Inputs}
The agent receives the following inputs:
\begin{itemize}[label=--]
    \item \textbf{Source}: [Specify source, e.g., user input, previous agent (name the agent)].
    \item \textbf{Format}: [Describe format, e.g., JSON, CSV, text prompt].
    \item \textbf{Details}: [Explain how inputs are processed, e.g., parsing JSON for column names, validating data types].
\end{itemize}

\textbf{Expected Content}: Provide a precise description of input sources, formats, and processing steps. Include examples (e.g., sample JSON or CSV structure) and any validation mechanisms to ensure input usability.

\subsection{Outputs}
The agent produces the following outputs:
\begin{itemize}[label=--]
    \item \textbf{Format}: [Describe format, e.g., CSV file, JSON report].
    \item \textbf{Details}: [Explain output structure, e.g., columns in a CSV, fields in a JSON].
    \item \textbf{Usability}: [Describe how outputs are used by the next agent, e.g., compatibility with PyCaret].
\end{itemize}

\textbf{Expected Content}: Specify the output format, structure, and how it ensures compatibility with the next agent in the pipeline. Include examples of expected output.

\subsection{Integration with LangGraph and Ollama}
The agent is implemented as a LangGraph node, using a pre-trained Ollama model for [specify NLP tasks, e.g., prompt parsing, result interpretation]. The agent’s logic is executed in Python, leveraging [list libraries, e.g., \texttt{pandas}, \texttt{faker}] for data processing.

\textbf{Expected Content}: Describe how the agent integrates into the LangGraph workflow (e.g., as a node with defined edges). Detail the use of Ollama (e.g., model selection, tasks performed) and Python libraries. Explain how state is managed between agents.

\section{Implementation}
This section details the technical implementation of the [Agent Name] Agent, including code structure, Ollama configuration, and prompt engineering.

\subsection{Code Structure}
The agent is implemented in Python, with the following components:

\begin{lstlisting}[language=Python, caption=Main Functions]
def parse_prompt(prompt):
    # Function to parse user prompt
    pass

def generate_data(specification):
    # Function to generate synthetic data
    pass
\end{lstlisting}

\textbf{Expected Content}: Provide a high-level overview of the code structure, including key functions, classes, or scripts. Include pseudocode or code snippets if necessary to illustrate critical logic.

\subsection{Ollama Configuration}
The agent uses a pre-trained Ollama model configured as follows:
\begin{itemize}[label=--]
    \item \textbf{Model}: [Specify model, e.g., LLaMA variant].
    \item \textbf{Temperature}: [Specify value, e.g., 0.3 for deterministic output].
    \item \textbf{Top-p}: [Specify value, e.g., 0.9 for nuanced responses].
\end{itemize}

\textbf{Expected Content}: Detail the Ollama model used, configuration parameters, and rationale (e.g., low temperature for precision). Explain how these settings affect output quality.

\subsection{Prompt Engineering}
The agent’s prompts are designed as follows:
\begin{itemize}[label=--]
    \item \textbf{Prompt Structure}: [Describe prompt format, e.g., “Generate Python code for...”].
    \item \textbf{Examples}: [Provide sample prompts and expected outputs].
    \item \textbf{Validation}: [Explain how prompts ensure valid outputs].
\end{itemize}

\textbf{Expected Content}: Provide the exact prompt structure, including instructions and examples. Describe how prompts are tested and refined to ensure reliable Ollama responses.

\section{Results}
This section presents the results of testing the [Agent Name] Agent on the five predefined use cases (e.g., fraud detection, customer analytics).

\textbf{Expected Content}: Describe the testing process, including use cases tested, input examples, and output results. Include metrics (e.g., accuracy of generated data, model performance) or qualitative assessments (e.g., report clarity). Provide tables or figures if applicable, e.g.:

\begin{table}[h]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Use Case} & \textbf{Result} \\ \hline
Fraud Detection & [e.g., Generated 1000-row dataset with 95\% column type accuracy] \\ \hline
Customer Analytics & [e.g., JSON report confirmed target suitability] \\ \hline
\end{tabular}
\caption{Test Results for [Agent Name] Agent}
\end{table}

\section{Discussion}
This section evaluates the agent’s performance, challenges encountered, and lessons learned.

\textbf{Expected Content}: Discuss the agent’s strengths (e.g., robust prompt parsing), limitations (e.g., handling ambiguous inputs), and challenges during development (e.g., debugging Ollama outputs). Suggest improvements for future iterations, such as enhanced prompt engineering or additional validation.

\section{Conclusion}
The [Agent Name] Agent successfully [summarise key achievement, e.g., generates well-formed synthetic data]. Its integration into the Project-X pipeline ensures [describe contribution, e.g., reliable inputs for model training]. Future work may include [briefly suggest next steps, e.g., supporting larger datasets].

\textbf{Expected Content}: Summarise the agent’s role, key achievements, and alignment with project goals. Highlight its readiness for integration and potential enhancements.

\section{References}
\begin{thebibliography}{9}
\bibitem{pycaret} PyCaret Documentation, \url{https://pycaret.org/}.
\bibitem{langgraph} LangGraph Framework, \url{https://langchain-ai.github.io/langgraph/}.
\bibitem{ollama} Ollama Documentation, \url{https://ollama.ai/}.
\end{thebibliography}

\textbf{Expected Content}: List all referenced materials, tools, or libraries used in development (e.g., \texttt{pycaret}, \texttt{faker}, LangGraph, Ollama). Use BibTeX format for consistency.

\section{Team Role}
The author, [Developer Name], serves as [team role, e.g., Frontend Developer], contributing to [describe additional contributions, e.g., UI design, system integration]. In the context of Project-X, these contributions supported [explain how role aided the project, e.g., seamless API integration].

\textbf{Expected Content}: Detail your additional role in the team and specific contributions beyond agent development. Explain how these efforts supported the broader project.

\end{document}
